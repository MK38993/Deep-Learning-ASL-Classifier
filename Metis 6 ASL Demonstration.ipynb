{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6a0d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, InputLayer\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "global base_dir\n",
    "base_dir=os.getcwd()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def index_images():\n",
    "    global mid_paths\n",
    "    mid_paths=[]\n",
    "    for chara in string.ascii_uppercase:\n",
    "        mid_paths.append(chara+'')\n",
    "    mid_paths.append('space')\n",
    "    mid_paths.remove('J') \n",
    "\n",
    "index_images()\n",
    "\n",
    "\n",
    "#SETUP FOR get_landmarks(). RUN FIRST\n",
    "\n",
    "def setup_hands(confidence=0.75):\n",
    "    global mpHands,hands,mpDraw\n",
    "    mpHands = mp.solutions.hands\n",
    "    hands = mpHands.Hands(max_num_hands=1, min_detection_confidence=confidence)\n",
    "    mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "setup_hands()\n",
    "\n",
    "\n",
    "def get_landmarks(image, draw=False, err=False):\n",
    "    framergb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    x , y, c = image.shape\n",
    "\n",
    "    # Get hand landmark prediction\n",
    "    result = hands.process(framergb)\n",
    "    # post process the result\n",
    "    if result.multi_hand_landmarks:\n",
    "        landmarks = []           \n",
    "        for handslms in result.multi_hand_landmarks:\n",
    "            for lm in handslms.landmark:\n",
    "                # print(id, lm)\n",
    "                lmx = int(lm.x * x)\n",
    "                lmy = int(lm.y * y)\n",
    "                landmarks.append([lmx, lmy])\n",
    "            if draw:\n",
    "                # Drawing landmarks on frames\n",
    "                mpDraw.draw_landmarks(image, handslms, mpHands.HAND_CONNECTIONS)\n",
    "        return(landmarks)\n",
    "    else:\n",
    "        if err:\n",
    "            print('Error: Hand not detected')\n",
    "        return('Error: Hand not detected')\n",
    "        \n",
    "\n",
    "        \n",
    "# Used to scale all landmarks to to palm of the hand\n",
    "\n",
    "\n",
    "def distance2d(a,b):\n",
    "    xd=a[0]-b[0]\n",
    "    yd=a[1]-b[1]\n",
    "    return((xd**2+yd**2)**0.5)\n",
    "\n",
    "\n",
    "\n",
    "# Scale all landmarks to the size of the palm of the hand\n",
    "# Accepts a Pandas row\n",
    "def reg_lm(landmarks):\n",
    "    #print(landmarks)\n",
    "    out_row=landmarks.copy()\n",
    "    p0,p5,p17=landmarks[0],landmarks[5],landmarks[17],\n",
    "    p5_p17_mp=[(landmarks[5][0]+landmarks[17][0])/2,(landmarks[5][1]+landmarks[17][1])/2]\n",
    "    palmh=distance2d(p0,p5_p17_mp)\n",
    "    palmw=distance2d(p5,p17)\n",
    "    #print(palmh,palmw)\n",
    "    try:\n",
    "        for i in range(21):\n",
    "            x_out=out_row[i][0]-p0[0]\n",
    "            y_out=out_row[i][1]-p0[1]\n",
    "            if float(x_out)!=0.0:\n",
    "                x_out/=palmw\n",
    "            if float(y_out)!=0.0:\n",
    "                y_out/=palmh\n",
    "            out_row.at[i]=[x_out,-1*y_out]\n",
    "    except:\n",
    "        #print(palmw,palmh,end=',')\n",
    "        pass\n",
    "    #out_row.iloc[0][0:21]\n",
    "    return(out_row)\n",
    "\n",
    "\n",
    "def to_sk_flat(image):\n",
    "    lmks=get_landmarks(image)\n",
    "    if type(lmks)==str:\n",
    "        return('NA')\n",
    "    lmks=pd.DataFrame([lmks]).iloc[0]\n",
    "    lmks=reg_lm(lmks)\n",
    "    lmks=np.array(lmks.to_list()).flatten()\n",
    "    return(lmks)\n",
    "    \n",
    "    \n",
    "    \n",
    "def predict_image(model,img,letter=False):\n",
    "    lmks=to_sk_flat(img)\n",
    "    if type(lmks)==str:\n",
    "        return('Hand not detected')\n",
    "    test_batch=np.zeros((32,42))\n",
    "    test_batch[0]=lmks\n",
    "    pred_matrix=model.predict(test_batch)[0]\n",
    "    pred=pred_matrix.argmax()\n",
    "    \n",
    "    if letter:\n",
    "        return(mid_paths[pred],pred_matrix[pred])\n",
    "    else:\n",
    "        return(pred,pred_matrix[pred])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "LMNN = Sequential()\n",
    "LMNN.add(InputLayer(input_shape=(42)))\n",
    "LMNN.add(Dense(96, activation='relu'))\n",
    "LMNN.add(Dense(256, activation='relu'))\n",
    "LMNN.add(Dense(128, activation='relu'))\n",
    "LMNN.add(Dense(64, activation='relu'))\n",
    "LMNN.add(Dense(26, activation='softmax'))\n",
    "LMNN.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "#LMNN.summary()\n",
    "\n",
    "LMNN=tf.keras.models.load_model(base_dir)\n",
    "\n",
    "\n",
    "print('Press X to stop image capture.')\n",
    "\n",
    "\n",
    "\n",
    "capture = cv2.VideoCapture(1)\n",
    "\n",
    "# Hold the background frame for background subtraction.\n",
    "background = None\n",
    "# Hold the hand's data so all its details are in one place.\n",
    "hand = None\n",
    "# Variables to count how many frames have passed and to set the size of the window.\n",
    "frames_elapsed = 0\n",
    "FRAME_HEIGHT = 720\n",
    "FRAME_WIDTH = 1280\n",
    "# Humans come in a ton of beautiful shades and colors.\n",
    "# Try editing these if your program has trouble recognizing your skin tone.\n",
    "CALIBRATION_TIME = 30\n",
    "BG_WEIGHT = 0.5\n",
    "OBJ_THRESHOLD = 18\n",
    "\n",
    "i=0\n",
    "\n",
    "sq_size=512\n",
    "sqh_off=500\n",
    "sqv_off=500\n",
    "\n",
    "while True:\n",
    "    i+=1\n",
    "    \n",
    "    # Store the frame from the video capture and resize it to the desired window size.\n",
    "    ret, frame = capture.read()\n",
    "    frame = frame[sqh_off:sqh_off+sq_size, sqv_off:sqv_off+sq_size]\n",
    "    #frame = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "    frame_copy=frame.copy()\n",
    "    p=predict_image(LMNN,frame_copy, True)\n",
    "    text_to_draw=str(p[0]+str(p[1]))\n",
    "    \n",
    "    get_landmarks(frame, True)\n",
    "    frame=cv2.flip(frame,1)\n",
    "    cv2.putText(frame,text_to_draw,(25,25),0,1,0)\n",
    "    cv2.imshow(\"Camera Input\", frame)\n",
    "\n",
    "\n",
    "    # Check if user wants to exit.\n",
    "    if (cv2.waitKey(1) & 0xFF == ord('x')):\n",
    "        break\n",
    "\n",
    "# When we exit the loop, we have to stop the capture too.\n",
    "# capture.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
