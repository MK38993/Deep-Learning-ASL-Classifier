{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e10f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, InputLayer\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "global base_dir\n",
    "base_dir=os.getcwd()\n",
    "base_dir='/Users/matthewkwee/Metis'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943764d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETUP FOR get_landmarks(). RUN FIRST\n",
    "\n",
    "def setup_hands(confidence=0.75, nhands=1):\n",
    "    global mpHands,hands,mpDraw\n",
    "    mpHands = mp.solutions.hands\n",
    "    hands = mpHands.Hands(max_num_hands=nhands, min_detection_confidence=confidence)\n",
    "    mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "setup_hands()\n",
    "\n",
    "\n",
    "def get_landmarks(image, draw=False, err=False):\n",
    "    framergb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    x , y, c = image.shape\n",
    "\n",
    "    # Get hand landmark prediction\n",
    "    result = hands.process(framergb)\n",
    "    # post process the result\n",
    "    if result.multi_hand_landmarks:\n",
    "        landmarks = []           \n",
    "        for handslms in result.multi_hand_landmarks:\n",
    "            for lm in handslms.landmark:\n",
    "                # print(id, lm)\n",
    "                lmx = int(lm.x * x)\n",
    "                lmy = int(lm.y * y)\n",
    "                landmarks.append([lmx, lmy])\n",
    "            if draw:\n",
    "                # Drawing landmarks on frames\n",
    "                mpDraw.draw_landmarks(image, handslms, mpHands.HAND_CONNECTIONS)\n",
    "        return(landmarks)\n",
    "    else:\n",
    "        if err:\n",
    "            print('Error: Hand not detected')\n",
    "        return('Error: Hand not detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0ad0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks_3d(image, draw=False, err=False):\n",
    "    framergb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    x , y, c = image.shape\n",
    "\n",
    "    # Get hand landmark prediction\n",
    "    result = hands.process(framergb)\n",
    "    # post process the result\n",
    "    if result.multi_hand_landmarks:\n",
    "        landmarks = []           \n",
    "        for handslms in result.multi_hand_landmarks:\n",
    "            for lm in handslms.landmark:\n",
    "                # print(id, lm)\n",
    "                lmx = int(lm.x * x)\n",
    "                lmy = int(lm.y * y)\n",
    "                landmarks.append([lmx, lmy,lm.z])\n",
    "            if draw:\n",
    "                # Drawing landmarks on frames\n",
    "                mpDraw.draw_landmarks(image, handslms, mpHands.HAND_CONNECTIONS)\n",
    "        return(landmarks)\n",
    "    else:\n",
    "        if err:\n",
    "            print('Error: Hand not detected')\n",
    "        return('Error: Hand not detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a109282",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_landmarks_3d(cv2.imread('WD_I.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff9c889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to scale all landmarks to to palm of the hand\n",
    "\n",
    "\n",
    "def distance2d(a,b):\n",
    "    xd=a[0]-b[0]\n",
    "    yd=a[1]-b[1]\n",
    "    return((xd**2+yd**2)**0.5)\n",
    "\n",
    "\n",
    "\n",
    "# Scale all landmarks to the size of the palm of the hand\n",
    "# Accepts a Pandas row\n",
    "def reg_lm(landmarks):\n",
    "    #print(landmarks)\n",
    "    out_row=landmarks.copy()\n",
    "    p0,p5,p17=landmarks[0],landmarks[5],landmarks[17],\n",
    "    p5_p17_mp=[(landmarks[5][0]+landmarks[17][0])/2,(landmarks[5][1]+landmarks[17][1])/2]\n",
    "    palmh=distance2d(p0,p5_p17_mp)\n",
    "    palmw=distance2d(p5,p17)\n",
    "    #print(palmh,palmw)\n",
    "    try:\n",
    "        for i in range(21):\n",
    "            x_out=out_row[i][0]-p0[0]\n",
    "            y_out=out_row[i][1]-p0[1]\n",
    "            if float(x_out)!=0.0:\n",
    "                x_out/=palmw\n",
    "            if float(y_out)!=0.0:\n",
    "                y_out/=palmh\n",
    "            out_row.at[i]=[x_out,-1*y_out]\n",
    "    except:\n",
    "        #print(palmw,palmh,end=',')\n",
    "        pass\n",
    "    #out_row.iloc[0][0:21]\n",
    "    return(out_row)\n",
    "\n",
    "\n",
    "def to_sk_flat(image):\n",
    "    lmks=get_landmarks(image)\n",
    "    if type(lmks)==str:\n",
    "        return('NA')\n",
    "    lmks=pd.DataFrame([lmks]).iloc[0]\n",
    "    lmks=reg_lm(lmks)\n",
    "    lmks=np.array(lmks.to_list()).flatten()\n",
    "    return(lmks)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9927f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model,img,letter=False):\n",
    "    lmks=to_sk_flat(img)\n",
    "    if type(lmks)==str:\n",
    "        return('Hand not detected')\n",
    "    test_batch=np.zeros((32,42))\n",
    "    test_batch[0]=lmks\n",
    "    pred_matrix=model.predict(test_batch)[0]\n",
    "    pred=pred_matrix.argmax()\n",
    "    \n",
    "    if letter:\n",
    "        return(mid_paths[pred],pred_matrix[pred])\n",
    "    else:\n",
    "        return(pred,pred_matrix[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f4af13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af4ac2ce",
   "metadata": {},
   "source": [
    "# Format dataset for easy usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273716e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_images():\n",
    "    #Index all filepaths in initial dataset\n",
    "    global base_filepath, mid_paths, all_paths\n",
    "    base_filepath=\"ASL/\"\n",
    "    mid_paths=[]\n",
    "    for chara in string.ascii_uppercase:\n",
    "        mid_paths.append(chara+'')\n",
    "    mid_paths.append('space')\n",
    "    mid_paths.remove('J')\n",
    "\n",
    "    all_paths={}\n",
    "    for m_path in mid_paths:\n",
    "        all_paths[m_path]=os.listdir(base_filepath+m_path)\n",
    "\n",
    "    try:\n",
    "        # Index all 64x64 images\n",
    "        os.chdir(base_dir)\n",
    "        global base_filepath_64, all_paths_64\n",
    "        base_filepath_64=\"ASL64/\"\n",
    "        all_paths_64={}\n",
    "        for m_path in mid_paths:\n",
    "            all_paths_64[m_path]=os.listdir(base_filepath_64+m_path)\n",
    "\n",
    "        # Index training 64x64 images\n",
    "        os.chdir(base_dir)\n",
    "        global train_filepath_64, train_paths_64\n",
    "        train_filepath_64=\"ASL64_train/\"\n",
    "        train_paths_64={}\n",
    "        for m_path in mid_paths:\n",
    "            train_paths_64[m_path]=os.listdir(train_filepath_64+m_path)\n",
    "            \n",
    "        # Index testing 64x64 images\n",
    "        os.chdir(base_dir)\n",
    "        global test_filepath_64, test_paths_64\n",
    "        test_filepath_64=\"ASL64_test/\"\n",
    "        test_paths_64={}\n",
    "        for m_path in mid_paths:\n",
    "            test_paths_64[m_path]=os.listdir(test_filepath_64+m_path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "index_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7222cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_CODE=False\n",
    "if RUN_CODE:\n",
    "    #Create directory for 64x64 images\n",
    "    os.chdir(base_dir)\n",
    "    os.mkdir(base_dir+'/ASL64/')\n",
    "    for m_path in mid_paths:\n",
    "        os.mkdir(base_dir+'/ASL64/'+m_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e03c6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "RUN_CODE=False\n",
    "if RUN_CODE:  \n",
    "    # Resize all images to 64x64 - easier to store, and easier for network to recognize\n",
    "    # There's distortion in images that gets ignored at lower resolutions\n",
    "    for m_path in mid_paths:\n",
    "        print(m_path,end='...')\n",
    "        for i in range(len(all_paths[m_path])):\n",
    "            os.chdir(base_dir)\n",
    "            image_path=base_filepath+m_path+'/'+all_paths[m_path][i]\n",
    "            image_full=cv2.imread(image_path)\n",
    "            image_full=cv2.resize(image_full, (64,64))\n",
    "            os.chdir(base_dir+'/ASL64/'+m_path)\n",
    "            image_name=all_paths[m_path][i].replace('.jpg','.png')\n",
    "            cv2.imwrite(all_paths[m_path][i],image_full)\n",
    "    os.chdir(base_dir)\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e3492",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c8c05a",
   "metadata": {},
   "source": [
    "# Create Train/Test split directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0686c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_CODE=False\n",
    "if RUN_CODE:\n",
    "    #Create train/test directories\n",
    "    os.chdir(base_dir)\n",
    "    os.mkdir(base_dir+'/ASL64_train')\n",
    "    for m_path in mid_paths:\n",
    "        os.mkdir(base_dir+'/ASL64_train/'+m_path)\n",
    "        \n",
    "    os.mkdir(base_dir+'/ASL64_test')\n",
    "    for m_path in mid_paths:\n",
    "        os.mkdir(base_dir+'/ASL64_test/'+m_path)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for m_path in mid_paths:\n",
    "        print(m_path,end='...')\n",
    "        for i in range(len(all_paths_64[m_path])):\n",
    "            os.chdir(base_dir)\n",
    "            image_path=base_filepath_64+m_path+'/'+all_paths_64[m_path][i]\n",
    "            img_array=cv2.imread(image_path)\n",
    "            image_name=all_paths_64[m_path][i].replace('.jpg','.png')\n",
    "            \n",
    "            if random.random()<0.2:\n",
    "                os.chdir(base_dir+'/ASL64_test/'+m_path)\n",
    "            else:\n",
    "                os.chdir(base_dir+'/ASL64_train/'+m_path)\n",
    "            cv2.imwrite(all_paths_64[m_path][i],img_array)\n",
    "    print('Done!')        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c0a840",
   "metadata": {},
   "source": [
    "# Create CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e384dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=image_dataset_from_directory('ASL64_train',image_size=(64, 64),label_mode=\"categorical\")\n",
    "\n",
    "CCNN = Sequential()\n",
    "\n",
    "CCNN.add(InputLayer(input_shape=(64,64,3)))\n",
    "CCNN.add(Conv2D(filters=8, kernel_size=3, activation='relu', padding='same'))\n",
    "CCNN.add(MaxPooling2D())\n",
    "CCNN.add(Conv2D(filters=16, kernel_size=5, activation='relu', padding='same'))\n",
    "CCNN.add(MaxPooling2D())\n",
    "CCNN.add(Conv2D(filters=24, kernel_size=7, activation='relu', padding='same'))\n",
    "CCNN.add(MaxPooling2D())\n",
    "CCNN.add(Conv2D(filters=32, kernel_size=9, activation='relu', padding='same'))\n",
    "CCNN.add(GlobalAveragePooling2D())\n",
    "CCNN.add(Dense(128, activation='relu'))\n",
    "CCNN.add(Dense(64, activation='relu'))\n",
    "CCNN.add(Dense(32, activation='relu'))\n",
    "CCNN.add(Dense(26, activation='softmax'))\n",
    "\n",
    "CCNN.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "CCNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b9ef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = EarlyStopping(monitor='loss', patience=5)\n",
    "CCNN.fit(images, epochs=128, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c42a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "CCNN.trainable=False\n",
    "CCNN.save(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0793e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "CCNN=tf.keras.models.load_model(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4f405d",
   "metadata": {},
   "source": [
    "# CNN Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e78a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model, batches):\n",
    "    print(f'Scoring model with {batches} batches of 32 - total {batches*32} images')\n",
    "    actuals=[]\n",
    "    preds=[]\n",
    "    seen=[]\n",
    "\n",
    "    failcounter=0\n",
    "    for b_num in range(batches):\n",
    "        test_batch=np.zeros((32,64,64,3))\n",
    "        print(b_num+1,end='.')\n",
    "        for i_num in range(32):\n",
    "\n",
    "            while True:\n",
    "                m_path=random.randint(0,len(mid_paths)-1)\n",
    "                m_path2=mid_paths[m_path]\n",
    "                i_n=random.randint(0,len(all_paths_64[m_path2])-1)\n",
    "                fullpath=base_filepath_64+m_path2+'/'+all_paths_64[m_path2][i_n]\n",
    "                if fullpath in seen:\n",
    "                    failcounter+=1\n",
    "                else:\n",
    "                    break\n",
    "                    \n",
    "            seen.append(fullpath)\n",
    "            testim=load_img(fullpath, grayscale=False, color_mode=\"rgb\", target_size=None, interpolation=\"nearest\")\n",
    "            testim=np.array(testim)\n",
    "            #plt.imshow(testim)\n",
    "            test_batch[i_num]=testim\n",
    "            actuals.append(m_path)\n",
    "\n",
    "\n",
    "        preds_soft=model.predict(test_batch)\n",
    "        for p_num in range(32):\n",
    "            preds_hard=preds_soft[p_num].argmax()\n",
    "            if preds_soft[p_num][preds_hard]<0.25:\n",
    "                preds_hard=-1\n",
    "            preds.append(preds_hard)\n",
    "    acc=accuracy_score(actuals,preds)\n",
    "    print(f'\\nFinished scoring model - {failcounter} re-samples that were replaced.')\n",
    "    return(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893d626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model(CCNN,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e9cd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch=np.zeros((32,64,64,3))\n",
    "fullpath=base_filepath_64+'A/'+all_paths_64['A'][0]\n",
    "image=load_img(fullpath, grayscale=False, color_mode=\"rgb\", target_size=None, interpolation=\"nearest\")\n",
    "#image=cv2.resize(image, (64,64))\n",
    "test_batch[0]=np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab058104",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=[]\n",
    "preds_soft=CCNN.predict(test_batch)\n",
    "for p_num in range(32):\n",
    "    preds_hard=preds_soft[p_num].argmax()\n",
    "    if preds_soft[p_num][preds_hard]<0.25:\n",
    "        preds_hard=-1\n",
    "    preds.append(preds_hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c96d4c4",
   "metadata": {},
   "source": [
    "# Reformat photos into groups of landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564a2187",
   "metadata": {},
   "outputs": [],
   "source": [
    "category=[]\n",
    "landmarks=[]\n",
    "name=[]\n",
    "\n",
    "failure=0\n",
    "total=0\n",
    "\n",
    "train_path_64='ASL64_train/'\n",
    "\n",
    "for m_path in mid_paths:\n",
    "    print(m_path,end='...')\n",
    "    print(failure/(total+1))\n",
    "    for i in range(len(train_paths_64[m_path])):\n",
    "        if i%50==0:\n",
    "            print(i,end='.')\n",
    "        fullpath=train_path_64+m_path+'/'+train_paths_64[m_path][i]\n",
    "        img=cv2.imread(fullpath)\n",
    "        #print (img)\n",
    "        lmarks=get_landmarks(img, False, False)\n",
    "        if type(lmarks)!=str:\n",
    "            landmarks.append(lmarks)\n",
    "            name.append(train_paths_64[m_path][i])\n",
    "            category.append(m_path)\n",
    "        else:\n",
    "            failure+=1\n",
    "        total+=1\n",
    "            \n",
    "df_landmarks_train=pd.DataFrame(landmarks)\n",
    "df_landmarks_train['category']=category\n",
    "df_landmarks_train['name']=name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d8dbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_CODE=False\n",
    "if RUN_CODE:\n",
    "    f=open('df_landmarks_train','wb')\n",
    "    pickle.dump(df_landmarks_train,f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d27e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "category=[]\n",
    "landmarks=[]\n",
    "name=[]\n",
    "\n",
    "failure=0\n",
    "total=0\n",
    "\n",
    "test_path_64='ASL64_test/'\n",
    "\n",
    "for m_path in mid_paths:\n",
    "    print(m_path,end='...')\n",
    "    print(failure/(total+1))\n",
    "    for i in range(len(test_paths_64[m_path])):\n",
    "        if i%50==0:\n",
    "            print(i,end='.')\n",
    "        fullpath=test_path_64+m_path+'/'+test_paths_64[m_path][i]\n",
    "        img=cv2.imread(fullpath)\n",
    "        #print (img)\n",
    "        lmarks=get_landmarks(img, False, False)\n",
    "        if type(lmarks)!=str:\n",
    "            landmarks.append(lmarks)\n",
    "            name.append(test_paths_64[m_path][i])\n",
    "            category.append(m_path)\n",
    "        else:\n",
    "            failure+=1\n",
    "        total+=1\n",
    "            \n",
    "df_landmarks_test=pd.DataFrame(landmarks)\n",
    "df_landmarks_test['category']=category\n",
    "df_landmarks_test['name']=name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4330a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_CODE=False\n",
    "if RUN_CODE:\n",
    "    f=open('df_landmarks_test','wb')\n",
    "    pickle.dump(df_landmarks_test,f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8725906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629b8ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=train_path_64+'A'+'/'+train_paths_64['A'][0]\n",
    "p=train_path_64+'A'+'/'+'A25.jpg'\n",
    "print(p)\n",
    "#p='WD_I.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82866bf0",
   "metadata": {},
   "source": [
    "### Shape of palm is measured by points 0, 5, 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afc9d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_landmarks_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270c7fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat train data\n",
    "\n",
    "RUN_CODE=False\n",
    "if RUN_CODE:\n",
    "    lmscale_rows=[]\n",
    "    for i in range(len(df_landmarks_train)):\n",
    "        if i%1000==0:\n",
    "            print(i,end='.')\n",
    "        lmscale_rows.append(reg_lm(df_landmarks_train.iloc[i]))\n",
    "\n",
    "\n",
    "    df_lmscale_train=pd.DataFrame(lmscale_rows)\n",
    "    df_lmscale_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1c1113",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_CODE=False\n",
    "if RUN_CODE:\n",
    "    f=open('df_lmscale_train','wb')\n",
    "    pickle.dump(df_lmscale_train,f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7084e5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat test data\n",
    "\n",
    "RUN_CODE=False\n",
    "if RUN_CODE:\n",
    "    lmscale_rows=[]\n",
    "    for i in range(len(df_landmarks_test)):\n",
    "        if i%1000==0:\n",
    "            print(i,end='.')\n",
    "        lmscale_rows.append(reg_lm(df_landmarks_test.iloc[i]))\n",
    "\n",
    "\n",
    "    df_lmscale_test=pd.DataFrame(lmscale_rows)\n",
    "    df_lmscale_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99b52af",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_CODE=False\n",
    "if RUN_CODE:\n",
    "    f=open('df_lmscale_test','wb')\n",
    "    pickle.dump(df_lmscale_test,f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b41ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7463f3f",
   "metadata": {},
   "source": [
    "# Change sets to numpy arrays for network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d23a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_CODE=False\n",
    "if RUN_CODE:\n",
    "\n",
    "    f=open('df_lmscale_train','rb')\n",
    "    df_lmscale_train=pickle.load(f)\n",
    "    f.close()\n",
    "    f=open('df_lmscale_test','rb')\n",
    "    df_lmscale_test=pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    df_lmscale_train=df_lmscale_train.sample(frac=1,random_state=hash('I CAN DO ANYTHING')%2**32)\n",
    "    df_lmscale_test=df_lmscale_test.sample(frac=1,random_state=hash('[[Hyperlink Blocked]]')%2**32)\n",
    "\n",
    "\n",
    "\n",
    "    X_train=[]\n",
    "    y_train=[]\n",
    "    for i in range(len(df_lmscale_train)):\n",
    "        X_train.append(df_lmscale_train.iloc[i][0:21].to_list())\n",
    "        y_train.append(mid_paths.index(df_lmscale_train.iloc[i]['category']))\n",
    "    X_train=np.array(X_train)\n",
    "    y_train=np.array(y_train)\n",
    "\n",
    "    \n",
    "    X_test=[]\n",
    "    y_test=[]\n",
    "    for i in range(len(df_lmscale_test)):\n",
    "        X_test.append(df_lmscale_test.iloc[i][0:21].to_list())\n",
    "        y_test.append(mid_paths.index(df_lmscale_test.iloc[i]['category']))\n",
    "    X_test=np.array(X_test)\n",
    "    y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7692ce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_CODE=False\n",
    "if RUN_CODE:\n",
    "    f=open('X_train','wb')\n",
    "    pickle.dump(X_train,f)\n",
    "    f.close()\n",
    "    f=open('y_train','wb')\n",
    "    pickle.dump(y_train,f)\n",
    "    f.close()\n",
    "    f=open('X_test','wb')\n",
    "    pickle.dump(X_test,f)\n",
    "    f.close()\n",
    "    f=open('y_test','wb')\n",
    "    pickle.dump(y_test,f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb18bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_CODE=True\n",
    "if RUN_CODE:\n",
    "    f=open('X_train','rb')\n",
    "    X_train=pickle.load(f)\n",
    "    f.close()\n",
    "    f=open('y_train','rb')\n",
    "    y_train=pickle.load(f)\n",
    "    f.close()\n",
    "    f=open('X_test','rb')\n",
    "    X_test=pickle.load(f)\n",
    "    f.close()\n",
    "    f=open('y_test','rb')\n",
    "    y_test=pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed713dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e952755",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape(len(X_train),42)\n",
    "X_test=X_test.reshape(len(X_test),42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f86818",
   "metadata": {},
   "source": [
    "# Create neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ab8184",
   "metadata": {},
   "outputs": [],
   "source": [
    "LMNN = Sequential()\n",
    "LMNN.add(InputLayer(input_shape=(42)))\n",
    "LMNN.add(Dense(96, activation='relu'))\n",
    "LMNN.add(Dense(256, activation='relu'))\n",
    "LMNN.add(Dense(128, activation='relu'))\n",
    "LMNN.add(Dense(64, activation='relu'))\n",
    "LMNN.add(Dense(26, activation='softmax'))\n",
    "LMNN.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "#LMNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fde4ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RUN_CODE=False\n",
    "if RUN_CODE:\n",
    "    callback = EarlyStopping(monitor='loss', patience=5)\n",
    "    LMNN.fit(X_train, y_train, batch_size=32,callbacks=[callback], verbose=True, validation_split=0.2, epochs=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee10d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_CODE=False\n",
    "if RUN_CODE:\n",
    "    LMNN.save(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5182f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LMNN=tf.keras.models.load_model(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f269db0e",
   "metadata": {},
   "source": [
    "# Run neural network using standardized skeleton positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8223919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_skeleton(model, batches):\n",
    "    \n",
    "    print(f'Scoring model with {batches} batches of 32 - total {batches*32} skeletons')\n",
    "    actuals=[]\n",
    "    preds=[]\n",
    "    seen=[]\n",
    "\n",
    "    failcounter=0\n",
    "    for b_num in range(batches):\n",
    "        test_batch=np.zeros((32,42))\n",
    "        print(b_num+1,end='.')\n",
    "\n",
    "        for i_num in range(32):\n",
    "            idx=random.randint(0,len(X_test)-1)\n",
    "            lmks=X_test[idx]\n",
    "            \n",
    "            test_batch[i_num]=lmks\n",
    "            actuals.append(y_test[idx].argmax())\n",
    "\n",
    "        preds_soft=model.predict(test_batch)\n",
    "        for p_num in range(32):\n",
    "            preds_hard=preds_soft[p_num].argmax()\n",
    "            if preds_soft[p_num][preds_hard]<0.25:\n",
    "                preds_hard=-1\n",
    "            preds.append(preds_hard)\n",
    "    acc=accuracy_score(actuals,preds)\n",
    "    print(f'\\nFinished scoring model - {failcounter} re-samples that were replaced.')\n",
    "    return(acc,actuals,preds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edf93d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=score_skeleton(LMNN,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f422be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=pd.DataFrame(data[1],data[2]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6956a44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3179bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy={}\n",
    "accuracyL=[]\n",
    "for i in range(26):\n",
    "    d2df=data_df[data_df['index']==i]\n",
    "    accuracy[mid_paths[i]]=len(d2df[d2df['index']==d2df[0]])/len(d2df['index'])\n",
    "    accuracyL.append(len(d2df[d2df['index']==d2df[0]])/len(d2df['index']))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f04b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.bar(mid_paths,accuracyL)\n",
    "plt.axis([-0.75,25.75,0.7,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3288df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyL.remove(0.821608040201005)\n",
    "accuracyL.remove(0.8892215568862275)\n",
    "min(accuracyL),accuracyL.index(min(accuracyL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0cb9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "UVDEQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da9ce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(d2df[d2df['index']==d2df[0]])/len(d2df['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7485418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47293c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4333045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(1)\n",
    "\n",
    "# Hold the background frame for background subtraction.\n",
    "background = None\n",
    "# Hold the hand's data so all its details are in one place.\n",
    "hand = None\n",
    "# Variables to count how many frames have passed and to set the size of the window.\n",
    "frames_elapsed = 0\n",
    "FRAME_HEIGHT = 720\n",
    "FRAME_WIDTH = 1280\n",
    "# Humans come in a ton of beautiful shades and colors.\n",
    "# Try editing these if your program has trouble recognizing your skin tone.\n",
    "CALIBRATION_TIME = 30\n",
    "BG_WEIGHT = 0.5\n",
    "OBJ_THRESHOLD = 18\n",
    "\n",
    "i=0\n",
    "\n",
    "sq_size=512\n",
    "sqh_off=500\n",
    "sqv_off=500\n",
    "\n",
    "while True:\n",
    "    i+=1\n",
    "    \n",
    "    # Store the frame from the video capture and resize it to the desired window size.\n",
    "    ret, frame = capture.read()\n",
    "    frame = frame[sqh_off:sqh_off+sq_size, sqv_off:sqv_off+sq_size]\n",
    "    frame=frame[len(frame):0:-1,len(frame):0:-1]\n",
    "    #frame = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "    frame_copy=frame.copy()\n",
    "    p=predict_image(LMNN,frame_copy, True)\n",
    "    text_to_draw=str(p[0]+str(p[1]))\n",
    "    \n",
    "    get_landmarks(frame, True)\n",
    "    cv2.putText(frame,text_to_draw,(25,25),0,1,0)\n",
    "    cv2.imshow(\"Camera Input\", frame)\n",
    "\n",
    "\n",
    "    # Check if user wants to exit.\n",
    "    if (cv2.waitKey(1) & 0xFF == ord('x')):\n",
    "        break\n",
    "\n",
    "# When we exit the loop, we have to stop the capture too.\n",
    "# capture.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c7a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_hands(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb73b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame=cv2.imread('WD_I.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32899f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "blank=cv2.imread('blank400.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f577bfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image(LMNN,frame, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da48288",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('tes2.png',frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27939b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dd46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "x , y, c = frame.shape\n",
    "\n",
    "# Get hand landmark prediction\n",
    "result = hands.process(framergb)\n",
    "# post process the result\n",
    "\n",
    "landmarks = []           \n",
    "for handslms in result.multi_hand_landmarks:\n",
    "    for lm in handslms.landmark:\n",
    "        # print(id, lm)\n",
    "        lmx = int(lm.x * x)\n",
    "        lmy = int(lm.y * y)\n",
    "        landmarks.append([lmx, lmy])\n",
    "    # Drawing landmarks on frames\n",
    "    mpDraw.draw_landmarks(blank, handslms, mpHands.HAND_CONNECTIONS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e4f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('hand400.png',blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a6bf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointsx=[landmarks[0][0], landmarks[5][0], landmarks[17][0]]\n",
    "pointsy=[landmarks[0][1], landmarks[5][1], landmarks[17][1]]\n",
    "\n",
    "plt.scatter(pointsx, pointsy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6b6144",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=to_sk_flat(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e2f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,8])\n",
    "plt.axis([-2,1,-0.1,2.5])\n",
    "plt.scatter(a[0::2],a[1::2], color='#f00',alpha=0.25)\n",
    "plt.scatter(a[0],a[1], color='#f00')\n",
    "plt.scatter(a[10],a[11], color='#f00')\n",
    "plt.scatter(a[34],a[35], color='#f00')\n",
    "plt.plot([a[0],a[10]],[a[1],a[11]],color='#f00')\n",
    "plt.plot([a[0],a[34]],[a[1],a[35]],color='#f00')\n",
    "plt.plot([a[10],a[34]],[a[11],a[35]],color='#f00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2a6a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8280d93e",
   "metadata": {},
   "source": [
    "# In case 2D recognition doesn't work, create standard \"bone lengths\" using my own hand.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3598f0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imt=cv2.imread('WD_I.png')\n",
    "#imt=cv2.imread(p)\n",
    "#imt=cv2.resize(imt, (64,64))\n",
    "lmsl=get_landmarks(imt)\n",
    "lmsl.append('WDI')\n",
    "lmsl.append('WD_I.png')\n",
    "lms=pd.DataFrame([lmsl])\n",
    "\n",
    "#lms=lms.transpose()\n",
    "r=reg_lm(lms.iloc[0])\n",
    "plt.imshow(imt)\n",
    "for item in lmsl[0:21]:\n",
    "    plt.scatter(item[0],item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c21f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164fc532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
